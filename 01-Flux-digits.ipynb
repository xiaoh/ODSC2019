{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br /><br /><br />\n",
    "# Recognizing handwritten digits using a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now reached the point where we can tackle a very interesting task: applying the knowledge we have gained with machine learning in general, and `Flux.jl` in particular, to create a neural network that can recognize handwritten digits! The data are from a data set called MNIST, which has become a classic in the machine learning world.\n",
    "\n",
    "[We could also try to apply the techniques to the original images of fruit instead. However, the fruit images are much larger than the MNIST images, which makes the learning a suitable neural network too slow.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data munging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we know, the first difficulty with any new data set is locating it, understanding what format it is stored in, reading it in and decoding it into a useful data structure in Julia.\n",
    "\n",
    "The original MNIST data is available [here](http://yann.lecun.com/exdb/mnist); see also the [Wikipedia page](https://en.wikipedia.org/wiki/MNIST_database). However, the format that the data is stored in is rather obscure.\n",
    "\n",
    "Fortunately, various packages in Julia provide nicer interfaces to access it. We will use the one provided by `Flux.jl`.\n",
    "\n",
    "The data are images of handwritten digits, and the corresponding labels that were determined by hand (i.e. by humans). Our job will be to get the computer to **learn** to recognize digits by learning, as usual, the function that relates the input and output data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and examining the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux, Flux.Data.MNIST, Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = MNIST.labels();\n",
    "images = MNIST.images();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that `images` is a `Vector`, i.e. an `Array{T, 1}` with a complicated parameter `T`. It has length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can just look at the first handful to get a sense of the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIKSURBVGje7dpPiI1RGMfxzyAL8qfZmFISi1EiFigpSZJiMbGhbLBDVjZ2FqSwQBazUhayxYryd6FuTf5syN6fHYM0yGDxvJPr3tu9c2eKc0/nW29v5z3ve3/93qdz3uc551IoFAqFQqHQ+/R1+8BMLKhrH8EcDOIwzmEvvuIMTjY8P+NfO8xfcFanG5ZgNjZiExZid4v7XuMihvAZz/EwBYf5C7Ydh2tx19/jrhU/cQBfqvZbfMCrFBzmL9g2hv2oYVmLvhpGsQXfdY7zf3OYv2DbufQ9jmMnnoq5Ep5hmxh3K3EsZYf5C04qp5kvvnHDOIj9uNYrDvMX7JjTwKfq/LE6H8J18R1M3mH+gl3VFnNxC5uxA3d6wWH+gl3Xh8vxROQz9zGCy/iVqsP8BbuOIVEDXsG8qn0CV/EuRYf5C04phrAK57G1ag/jFN6k5jB/wSnHkFiz2SXGZB/uiZojKYf5C04rhhN8EwnuD2zHg5Qc5i84qdqiFauxB+vqfuQFHqXmMH/BrmM4iKMirxmouz4ucppONWP+rzTduXQA+8T+0tKGvhGRz9xM0WH+gh1juEisiV7Cioa+Gs7ihsmv2eT/StOJYb+oF9Zo3rd4LOqK2xhL3WH+gk0x3CD2KtZjcUPfGC7gtD97hck7zF+wKacZqo4JXoo10nHxP4vRXnOYv2ChUCgUps9vDE1MYMzifHwAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAIWSURBVGje7dlPiE1RHAfwzwx5jWQWNtRkxw6vNxErskRRFpLMVklNkbJAVhb+LFCipIgiWRDJZuqtbPzb20kpTMKkKHMtzpVHc999b5TOnM63Tt13zv3db9/z7fc7v3sfGRkZGRkZGQP/EjyKAxjDdVzA85qYwf+tMH3CWXvYxAQWd8x9wpLYFKZPOH82QetwF8Mo8AXfBf824Fn5OwqF6RP2lYcL0cINjJTBhVA/T+FWOXcMJ2NRmD5hX3l4GbtnmG9hEdrYhFUxKUyfsGcPR7HV78Rt4wFO4y1e4CM2657c6W9pnLW06c/+5ZGQjxuxGlfwvlz7ga/l2kw9avpbGl8ersRhoX/5IOTcNUzhYTn+xhAOYU8MCtMn7OphA2ewReg9x/BU8KgOy2NRmD5hVw9bgn+wXTgD55zC9Am7enhWODDbevdvENOqD9r0tzQeD7cJvUyB+308cLqMeRmLwvQJKz0cwgK8w+0eHtTAifJ6AkdiUZg+YW1f+k3oRbuhgaNC//pGqMFTsShMn7DWw7o62hS824V72BmbwvQJKz0cKMcOjFfcc1DIv2HcFN49olOYPmGlh0U5luI8rmIS67EXa4Tv3q/xGBdjVZg+YW0tnYf9Qo38jBUda0+E/uV4zArTJ6z8XjqCO1jbcWNRXk8K/zON6x/pb2k8HsIy7BPOvF8ensMlvJorCtMnzMjIyMjIyOAnQ85TpVMJlhIAAAAASUVORK5C\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGlSURBVGje7dixS5VRHMbxj3IJWhILESGCBmmzqSEHCy5EtDcpbhr0bzQFzk0ODjVGOjU0OVmko5EJQVJDWyAkgVDDe8Dee68k773kuT/Osxzuue99vuc5D+d9uS9FRUVFRUVFRcOvkUEbtvECd7DX4/vR/50wPrDVOTGHK3jV0PAWtnNKGB/Y1eFdTGvW4Siu45rTD3j8LT3/Dhex1dBsCkt4jo+5JIwP7OqwnxWspnE/p4TxgbUOZzDZh9lYGt/klDA+sNbhA1xsaDSpehbCt5wSxgfWOryRxt0GRiuqHj/hMKeE8YGtXpPvz/jjS7iPBdxLc0/wI6eE8YE9O7zc8flmWlkbV3EB82nuCO/wK5nt5JYwPrD2N+4ZHqnO0cFf8zPpwmP8xAdVb9vYxHd8xbiq36wSxgfWzuFjfMFsx0UH2FB197aHyTIm8DnHhPGBXffSpw1M2ml8mWPC+MBW/xYnWs8xYQEWYP7AgZ3DEdW78n+9a42/pcPb4e8zrj7+lg5vh3Aba7kljA8c6L00y4TxgQPp8DUe5powPrCoqKioqH/9ATeSLmyCLr3XAAAAAElFTkSuQmCC\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAF/SURBVGje7dixShxRGIbhxyVgYaEhglhlr0C8gC1SJGKRwsqU5gbSCVqksQukEkkdsU/hBSjaLHgH2ggpUsTKwsrCpJiBXYVkZ3YX58zP+apzYJh3Xz7+M4clJycnJycnJ6f9mZnWiz5jDx28wfk/nus8t2F84ItpvOQjdvFQ7v+kZBgfOJUOX2M2VcP4wIk7fItP5foS7/E7JcP4wIk67OEQ8+X+K36mZhgfOFGHW1gu12c4StEwPnDse+mi4sx8wC0+4DRFw/jAseawix9D+wPV+mvEMD5wrA7XsVKuT7CfsmF8YO2zdENxj5lDH5v+fw9t3DA+sNYcdj0+Q6/V668Rw/jAWh3uGPwXA1/aYBgfWLnDVawN7Y9x1QbD+MDK38MbvCzXF4p7zV0bDOMDK8/hK4Nz9Jvx+mvEMD6wUoffn/yyfpsM4wNHdriKd4oZvFfMYN27aKOG8YEjO1zAUrn+he22GWZgBqYPHDmHl4rvX6+thvGBOTk5OTmT5y9D7yxecgVygwAAAABJRU5ErkJg\"></td><td style='text-align:center;vertical-align:middle; margin: 0.5em;border:1px #90999f solid;border-collapse:collapse'><img style='max-width: 100px; max-height:100px;display:inline' src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAHwSURBVGje7dnPi41RHMfx10j5kSShbCwMG2QjWRkbsZNYjAWFnYWdkpKN8QfY2LAgqWlEyWxk49dmyk4ZJVaajZKUSJlr8T23mabmzr2Pmnvu6Xw29/l1nvf93M/9PufHQ1VVVVVVVVVVVVVV1f9rqNcGB3AGI9idjl3CDA7iPqY6tF+x3A7LB/aU4ShuYlNq+AKbsWvezR7iVE4Oyweu7Pai/biNtXiF63iDVZjAkXTt29wclg/sKsPTuJO2n4t6/JH2R83l9wX3cnNYPnDJZ+kYrqCFW7hqLj+Yxs60fRJPcnNYPrBjHV4T+f3BM1zGr3Rutai/beKPMGbp/PrisHzgonW4AR/E+GUSx+ed24EH2Jf2H+E8fubosHzgohluEfMF2I7fOIdj2IN14vnawgk8zdVh+cCOdTgt5g5DIqu2ZtKxrfiaPrN1WD5w0f7wu3h+TmIjPon+7i6+YVxkN567w/KBHcc0U6IOF2oEhzCLz7k7LB/Y1fxwodaI/FpqHWYA7Hm9tK2/IsN2n5itw/KBjerw6CA5LB/YKMPhQXJYPrBRhq/TN50dBIflAxtl+A4fxdx/WO0P+wxsPKY5K95lvMRFvM/VYfnAxhmuF+8ND+OxWIer66V9ATbOkMjxBi5gr+5qsfyfdNmBVYOvfxOISKianOH0AAAAAElFTkSuQmCC\"></td></tr></tbody></table><div><small>(a vector displayed as a row to save space)</small></div>"
      ],
      "text/plain": [
       "5-element Array{Array{Gray{Normed{UInt8,8}},2},1}:\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]\n",
       " [Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); … ; Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0); Gray{N0f8}(0.0) Gray{N0f8}(0.0) … Gray{N0f8}(0.0) Gray{N0f8}(0.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×5 LinearAlgebra.Adjoint{Int64,Array{Int64,1}}:\n",
       " 5  0  4  1  9"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[1:5]' # transposed to match the above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the $i$th entry of the array is the data for the $i$th image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array{Gray{Normed{UInt8,8}},2}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the fruit images from the start of the course, the image is an array of color blocks, except that now each pixel just has a grey scale.\n",
    "\n",
    "To see the actual numeric content of the image, we can do, for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{Float64,2}:\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.498039  0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.25098   0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " ⋮                             ⋮         ⋱                 ⋮         \n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.215686  0.67451      0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.533333  0.992157     0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0       …  0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0       0.0          0.0       0.0  0.0  0.0  0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Float64.(images[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous notebooks, we arranged the input data for Flux as a `Vector` of `Vector`s.\n",
    "Now we will use an alternative arrangement, as a matrix, since that allows `Flux` to use matrix operations, which are more efficient.\n",
    "\n",
    "The column $i$ of the matrix is a vector consisting of the $i$th data point $\\mathbf{x}^{(i)}$.  Similarly, the desired outputs are given as a matrix, with the $i$th column being the desired output $\\mathbf{y}^{(i)}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = unique(length.(images))[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_outputs = length(unique(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the features\n",
    "\n",
    "We want to create a vector of feature vectors, each with the floating point values of the 784 pixels.\n",
    "\n",
    "An image is a matrix of colours, but now we need a vector of floating point numbers instead. To do so, we just arrange all of the elements of the matrix in a certain way into a single list; fortunately, Julia already provides the function `vec` to do so!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a subset of $N=5,000$ of the total $60,000$ images available in order to hold out test images that our model hasn't been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "preprocess (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(img) = vec(Float64.(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = preprocess.(images[1:5000]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating the labels\n",
    "\n",
    "We can just use `Flux.onehot` to create them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000-element Array{Flux.OneHotVector,1}:\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " ⋮\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
       " [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
       " [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
       " [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = [Flux.onehot(label, 0:9) for label in labels[1:5000]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the batched matrices for efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a function so we can easily create independent batches from arbitrary segments of the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_batch (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_batch(r)\n",
    "    xs = [preprocess(img) for img in images[r]]\n",
    "    ys = [Flux.onehot(label, 0:9) for label in labels[r]]\n",
    "    return (Flux.batch(xs), Flux.batch(ys))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll train our model on the first 5000 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0; … ; 0.0 0.0 … 0.0 0.0; 0.0 0.0 … 0.0 0.0], Bool[0 1 … 0 0; 0 0 … 0 0; … ; 0 0 … 0 0; 0 0 … 1 0])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainbatch = create_batch(1:10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "testbatch = create_batch(10001:20000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we must set up a neural network. Since the data is complicated, we may expect to need several layers.\n",
    "But we can start with a single layer.\n",
    "\n",
    "- The network will take as inputs the vectors $\\mathbf{x}^{(i)}$, so the input layer has $n$ nodes.\n",
    "\n",
    "- The output will be a one-hot vector encoding the digit from 1 to 9 or 0 that is desired. There are 10 possible categories, so we need an output layer of size 10.\n",
    "\n",
    "It is then our task as neural network designers to insert layers between these input and output layers, whose weights will be tuned during the learning process. *This is an art, not a science*! But major advances have come from finding a good structure for the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(Dense(784, 10), softmax)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(Dense(n_inputs, n_outputs, identity), softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L (generic function with 1 method)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(x,y) = Flux.crossentropy(model(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Descent(0.1)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = Descent()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.086626 seconds (10.31 k allocations: 66.679 MiB)\n",
      "  0.060217 seconds (419 allocations: 66.212 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(L, params(model), [trainbatch], opt)\n",
    "@time Flux.train!(L, params(model), [trainbatch], opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see what the total current loss is (after training just a handful to times above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1825838f0 (tracked)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(trainbatch...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.073117 seconds (419 allocations: 66.212 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Flux.train!(L, params(model), [trainbatch], opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0827324f0 (tracked)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L(trainbatch...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `train!` function can take an optional keyword argument, `cb` (short for \"**c**all**b**ack\"). A callback function is a function that you provide as an argument to a function `f`, which \"calls back\" your function every so often.\n",
    "\n",
    "This provides the possibility to provide a function that is called at each step or every so often during the training process.\n",
    "A common use case is to provide a visual trace of the training process by printing out the current value of the `loss` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L(trainbatch...) = 1.9922386f0 (tracked)\n",
      "L(trainbatch...) = 1.9091614f0 (tracked)\n",
      "L(trainbatch...) = 1.8324964f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "callback() = @show(L(trainbatch...))\n",
    "\n",
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 3), opt; cb = callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, it is expensive to calculate the complete `loss` function and it is not necessary to output it every step. So `Flux` also provides a function `throttle`, that provides a mechanism to call a given function at most once every certain number of seconds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L(trainbatch...) = 1.7616191f0 (tracked)\n",
      "L(trainbatch...) = 1.0796915f0 (tracked)\n",
      "L(trainbatch...) = 0.8493761f0 (tracked)\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 40), opt; cb = Flux.throttle(callback, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, that's just measuring the loss over the same data it's training on. It'd be more representative to test against novel data. In fact, let's track the performance of both as we continue training our model. In order to do so, we need to create a batch of test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "show_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Printf\n",
    "function show_loss()\n",
    "    train_loss = L(trainbatch...).data\n",
    "    test_loss  = L(testbatch...).data\n",
    "    @printf(\"train loss = %.3f, test loss = %.3f\\n\", train_loss, test_loss)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.807, test loss = 0.847\n",
      "train loss = 0.692, test loss = 0.733\n",
      "train loss = 0.626, test loss = 0.667\n",
      "train loss = 0.580, test loss = 0.622\n",
      "train loss = 0.546, test loss = 0.589\n",
      "train loss = 0.520, test loss = 0.563\n"
     ]
    }
   ],
   "source": [
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 100), opt;\n",
    "            cb = Flux.throttle(show_loss, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have trained a model, i.e. we have found the parameters `W` and `b` for the network layer(s). In order to **test** if the learning procedure was really successful, we check how well the resulting trained network performs when we test it with images that the network has not yet seen!\n",
    "\n",
    "Often, a dataset is split up into \"training data\" and \"test (or validation) data\" for this purpose, and indeed the MNIST data set has a separate pool of training data. We can instead use the images that we have not included in our reduced training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGiSURBVGje7dm/S1VhHMfxV3EvZqiDQ4NYm6KjXAQF5xapSXAPmsJBCAQd9S9ocmhraGwKIdCWoCkaIhyChoioloZAatLhXPBS53hvdvI8PXzf03N+fT98zofnnO9zDkEQBEEQXKo6cAcvcViz4OWLdpi/YGmGa9jBG6zg84DFZjCBg5Qc5i/YKts5jBEsYspgGU5jDx/xGt9ScZi/YGmG189RaBU3FNlPiAwvkNIM7+H4nAWf421KDkMwBEMwBP89rb8vUc0SXjTtMH/B0rXFNja743U86FNkCF8wih94hGWMYQO7TTrMX7B0Hn7vGXfOuLiDcbQV+cEV3O05Z65ph/kL9n2WzuIx3mHhl2Nzigyr+KCYn406zF+wb4YdZ8/FMr4q1vqreN+0w/wFa+9pXuG26m87+d/SNHqaJdzHrQEKPMEk5rvbU36fe406zF+w8r9FG1u41rPvmaJn+aR4vj5U9KHDTr+tRYbpZPgnDOGoO44M/8/34XLKDvMXrCXDpyk7zF+wtr70CFdTdJi/YC0Z/sRN7KfoMH/BIAiCIAg4AWbbMaYvtTF3AAAAAElFTkSuQmCC",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Tracked 10-element Array{Float32,1}:\n",
       " 0.0022264877f0\n",
       " 7.498947f-5\n",
       " 0.012713092f0\n",
       " 0.00062907155f0\n",
       " 0.96550006f0\n",
       " 8.5093896f-5\n",
       " 0.007303311f0\n",
       " 0.0014931796f0\n",
       " 0.0018345749f0\n",
       " 0.008140193f0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 11009\n",
    "display(images[i])\n",
    "display(labels[i])\n",
    "model(preprocess(images[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "What percent of images are we correctly classifying if we take the highest element to be the chosen answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "prediction (generic function with 1 method)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction(i) = findmax(model(preprocess(images[i])))[2]-1 # returns (max_value, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8804"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction(i) == labels[i] for i in 1:5000)/5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8734"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(prediction(i) == labels[i] for i in 5001:10000)/5000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we have used a single layer. In order to improve the prediction, we probably need to use more layers. Try adding more layers yourself and see how the performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADAM(0.001, (0.9, 0.999), IdDict{Any,Any}())"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_hidden = 20\n",
    "model = Chain(Dense(n_inputs, n_hidden, relu),\n",
    "        Dense(n_hidden, n_hidden, relu),\n",
    "        #Dense(n_hidden, n_hidden, relu),\n",
    "              Dense(n_hidden, n_outputs, identity), softmax)\n",
    "L(x,y) = Flux.crossentropy(model(x), y)\n",
    "opt = ADAM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 0.003, test loss = 0.517\n",
      "train loss = 0.003, test loss = 0.520\n",
      "train loss = 0.003, test loss = 0.523\n",
      "train loss = 0.003, test loss = 0.525\n",
      "train loss = 0.003, test loss = 0.528\n",
      "train loss = 0.003, test loss = 0.531\n",
      "train loss = 0.003, test loss = 0.534\n",
      "train loss = 0.003, test loss = 0.536\n",
      "train loss = 0.002, test loss = 0.539\n",
      "train loss = 0.002, test loss = 0.542\n",
      "train loss = 0.002, test loss = 0.544\n",
      "train loss = 0.002, test loss = 0.547\n",
      "train loss = 0.002, test loss = 0.549\n",
      "train loss = 0.002, test loss = 0.552\n",
      "train loss = 0.002, test loss = 0.554\n",
      "train loss = 0.002, test loss = 0.557\n",
      "train loss = 0.002, test loss = 0.559\n",
      "train loss = 0.002, test loss = 0.562\n",
      "train loss = 0.002, test loss = 0.564\n",
      "train loss = 0.002, test loss = 0.567\n",
      "train loss = 0.002, test loss = 0.569\n",
      "train loss = 0.002, test loss = 0.572\n",
      "train loss = 0.002, test loss = 0.574\n",
      "train loss = 0.002, test loss = 0.576\n",
      "train loss = 0.002, test loss = 0.578\n",
      "train loss = 0.001, test loss = 0.580\n",
      "train loss = 0.001, test loss = 0.583\n",
      "train loss = 0.001, test loss = 0.585\n",
      "train loss = 0.001, test loss = 0.587\n",
      "train loss = 0.001, test loss = 0.589\n",
      "train loss = 0.001, test loss = 0.591\n",
      "train loss = 0.001, test loss = 0.593\n"
     ]
    }
   ],
   "source": [
    "train_loss = Float64[]\n",
    "test_loss = Float64[]\n",
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 500), opt;\n",
    "            cb = Flux.throttle(show_loss, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 2.410, test loss = 2.382\n",
      "train loss = 1.446, test loss = 1.420\n",
      "train loss = 0.829, test loss = 0.844\n",
      "train loss = 0.545, test loss = 0.589\n",
      "train loss = 0.414, test loss = 0.478\n",
      "train loss = 0.337, test loss = 0.417\n",
      "train loss = 0.287, test loss = 0.381\n",
      "train loss = 0.251, test loss = 0.359\n",
      "train loss = 0.224, test loss = 0.345\n",
      "train loss = 0.201, test loss = 0.336\n",
      "train loss = 0.183, test loss = 0.330\n",
      "train loss = 0.167, test loss = 0.327\n",
      "train loss = 0.153, test loss = 0.326\n",
      "train loss = 0.141, test loss = 0.326\n",
      "train loss = 0.130, test loss = 0.328\n",
      "train loss = 0.120, test loss = 0.330\n",
      "train loss = 0.111, test loss = 0.333\n"
     ]
    }
   ],
   "source": [
    "train_loss = Float64[]\n",
    "test_loss = Float64[]\n",
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 500), opt;\n",
    "            cb = Flux.throttle(show_loss, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss = 2.290, test loss = 2.290\n",
      "train loss = 1.553, test loss = 1.562\n",
      "train loss = 0.758, test loss = 0.800\n",
      "train loss = 0.445, test loss = 0.526\n",
      "train loss = 0.324, test loss = 0.432\n",
      "train loss = 0.254, test loss = 0.388\n",
      "train loss = 0.202, test loss = 0.360\n",
      "train loss = 0.164, test loss = 0.344\n",
      "train loss = 0.133, test loss = 0.335\n",
      "train loss = 0.106, test loss = 0.332\n",
      "train loss = 0.086, test loss = 0.335\n",
      "train loss = 0.069, test loss = 0.343\n",
      "train loss = 0.055, test loss = 0.354\n",
      "train loss = 0.043, test loss = 0.368\n",
      "train loss = 0.033, test loss = 0.382\n",
      "train loss = 0.026, test loss = 0.396\n",
      "train loss = 0.020, test loss = 0.411\n",
      "train loss = 0.016, test loss = 0.425\n"
     ]
    }
   ],
   "source": [
    "train_loss = Float64[]\n",
    "test_loss = Float64[]\n",
    "Flux.train!(L, params(model), Iterators.repeated(trainbatch, 500), opt;\n",
    "            cb = Flux.throttle(show_loss, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAGzSURBVGje7dg7a1VBFMXxX8QXF1JJojFglUY0ItjY2Ilol84vYKF+hcQ6QbBQEBs/gY2d+EDQwkZIIYik0DLYmMLC+AK1mAk5iMWcU3jnbmbB4ezNmcufdRczwwxNTU1NTU1NTU1N49dUn8GLeIyjeIOz+NYTuOd/O4wP3Fs68CAe4Qh+YT8OSBmewRw28L42h/GBxRnekeYffMV1fMZ5PMRIyvBEbQ7jA4szvNSpb+FFrk9K+cF0jQ7jA4v2w3N4Kq2fm7iId/nbLD7mehPHanMYH1g0D2ek/OCK3fxgX6der9FhfGDxWrqjL3/1Dzr1qOD38f/S+jO8i+d4nftTnW/Ha3QYH1iU4Qa2cEg6Iy7+Y8wPXK3RYXxg8Rn/NO7lej4/Xa1huUaH8YG97ml2NI8LuJ/7FdzGdo0O4wN774eks8RMp/+gLL+xOIwPHJThZaxOisP4wEEZLnTqV3hWs8P4wN774UhaO2dzfxifanYYH9h7Hl6zm99L6d67aofxgb0zXMrvt7iJn7U7jA8ctB+S7tyeTILD+MDBGU7h9yQ4jA8clOF33JgUh/GBTU1N49cfriYzkMVgUgsAAAAASUVORK5CYII=",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                 ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(images[7010])\n",
    "labels[7010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tracked 10-element Array{Float32,1}:\n",
       " 8.117247f-5\n",
       " 3.4368663f-6\n",
       " 2.2509652f-5\n",
       " 0.0084966095f0\n",
       " 0.09988375f0\n",
       " 0.020022659f0\n",
       " 2.5050887f-5\n",
       " 0.0046520564f0\n",
       " 0.09729713f0\n",
       " 0.7695156f0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(preprocess(images[7010]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What about image structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a final note, notice that our model doesn't take into account any aspect of the image's connected-ness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHAAAABwCAAAAADji6uXAAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAALnSURBVGje7dpPiFdVFAfwz3PGJCYayYXVQEoRs7AEcaEMCEMxSS4GbWwjDLgQF9EqiApFUBAVIVz4B6I2BS1qMGlRYDAEQjQgBNWuWhikgjBYFFL2yxb3vvndeb5xRsF5zuV9N79zzr33dzjvcM69555biDiCdyLdQU+kf8Q57NdFB6tw3e1I1x7F25XxZRYZ+Sss4DxemmfiAH7DabxWM/48foh06seUbsTC/BUWJfE+9tRM2C7471RFXvXTo/gr8uvwITbiPext0sL8FbZY+ijgG2G/m6yZsDrK11Xk1TiU8DswEfll+C9Zl39YNJNLOxjEz/hDyIulj57CMEaxE5ewxuwc+QnG1Pu0gxfxNS40YWH+Cmd82HOHSY/jaqRH8TnewLtR9gvWqvfhFDY1aWH+ClssfRTwBbaqj8Wf8HRl7DFcMzvupjAU+Rt4KI7/jv5kbf5hsegKe2GbsAfW4VlJARIxjQ8qsqGEfhi7It1fmZf/J30w90NCrG7DP0KMpRgUzq4Dke/gDF7X1vgtWiwABRzCgcpAta77DhvMHbPr8X2kv8TLkW7j8L5jJpcSvvVmfItXcFbY+/rxauTHhXvwi+au8VP+JpZHfrAJC/NXWNzrwuN4M9IdwU9p3E7ihQfBwvwVtmjRonnccy7t0+01TQr93vPJ+Fxnn/xTWzM1/kLqwxJP4Iqu/wj73nWsjHxHuB+Ht3CsSQvzV9hi6aMg3H9OR8GtKPxY974MnsRlfCb0B1P0CPVH+R8HcDLyR4X704PxN/+waKa2WKn+fVOKrzBiYXl3HB9F+l8xYTdlYf4Ke+EEds8zcST+1vnvGeFcsyby/br9iuWVufl/0nY/bHHXmLO2GBbeT5T4Gyvc3Rk2XVci/7BoJpcy2ze/Cu9oSrlkrHwjcwOPRNlh7Iv0hFBX9OE5s/3XiIX5K2yx9FEQ+u5/6sZaWmvUvcX4VOhrpH2KMeFNf4kL2FKjMP+wWHSF/wPS4YVEVhM+EwAAAABJRU5ErkJggg==",
      "text/plain": [
       "28×28 Array{Gray{N0f8},2} with eltype Gray{Normed{UInt8,8}}:\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)    …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.729)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.776)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.992)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.765)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.992)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.714)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.992)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.51)      Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " ⋮                                   ⋱                   \n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.992)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.071)  …  Gray{N0f8}(0.0)  Gray{N0f8}(0.969)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.063)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.627)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)    …  Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.0)       Gray{N0f8}(0.0)  Gray{N0f8}(0.0)\n",
       " Gray{N0f8}(0.0)  Gray{N0f8}(0.035)     Gray{N0f8}(0.0)  Gray{N0f8}(0.0)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "p = randperm(28)\n",
    "images[1][p,p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.21568627450980393, 0.5333333333333333, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6745098039215687, 0.9921568627450981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07058823529411765, 0.8862745098039215, 0.9921568627450981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19215686274509805, 0.07058823529411765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6705882352941176, 0.9921568627450981, 0.9921568627450981, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.11764705882352941, 0.9333333333333333, 0.8588235294117647, 0.3137254901960784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09019607843137255, 0.8588235294117647, 0.9921568627450981, 0.8313725490196079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1411764705882353, 0.9921568627450981, 0.9921568627450981, 0.611764705882353, 0.054901960784313725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25882352941176473, 0.9921568627450981, 0.9921568627450981, 0.5294117647058824, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3686274509803922, 0.9921568627450981, 0.9921568627450981, 0.4196078431372549, 0.00392156862745098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09411764705882353, 0.8352941176470589, 0.9921568627450981, 0.9921568627450981, 0.5176470588235295, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6039215686274509, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.6039215686274509, 0.5450980392156862, 0.043137254901960784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4470588235294118, 0.9921568627450981, 0.9921568627450981, 0.9568627450980393, 0.06274509803921569, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.011764705882352941, 0.6666666666666666, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.7450980392156863, 0.13725490196078433, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15294117647058825, 0.8666666666666667, 0.9921568627450981, 0.9921568627450981, 0.5215686274509804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07058823529411765, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.803921568627451, 0.35294117647058826, 0.7450980392156863, 0.9921568627450981, 0.9450980392156862, 0.3176470588235294, 0.0, 0.0, 0.0, 0.0, 0.5803921568627451, 0.9921568627450981, 0.9921568627450981, 0.7647058823529411, 0.043137254901960784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07058823529411765, 0.9921568627450981, 0.9921568627450981, 0.7764705882352941, 0.043137254901960784, 0.0, 0.00784313725490196, 0.27450980392156865, 0.8823529411764706, 0.9411764705882353, 0.17647058823529413, 0.0, 0.0, 0.1803921568627451, 0.8980392156862745, 0.9921568627450981, 0.9921568627450981, 0.3137254901960784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.07058823529411765, 0.9921568627450981, 0.9921568627450981, 0.7137254901960784, 0.0, 0.0, 0.0, 0.0, 0.6274509803921569, 0.9921568627450981, 0.7294117647058823, 0.06274509803921569, 0.0, 0.5098039215686274, 0.9921568627450981, 0.9921568627450981, 0.7764705882352941, 0.03529411764705882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.49411764705882355, 0.9921568627450981, 0.9921568627450981, 0.9686274509803922, 0.16862745098039217, 0.0, 0.0, 0.0, 0.4235294117647059, 0.9921568627450981, 0.9921568627450981, 0.36470588235294116, 0.0, 0.7176470588235294, 0.9921568627450981, 0.9921568627450981, 0.3176470588235294, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5333333333333333, 0.9921568627450981, 0.984313725490196, 0.9450980392156862, 0.6039215686274509, 0.0, 0.0, 0.0, 0.00392156862745098, 0.4666666666666667, 0.9921568627450981, 0.9882352941176471, 0.9764705882352941, 0.9921568627450981, 0.9921568627450981, 0.788235294117647, 0.00784313725490196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6862745098039216, 0.8823529411764706, 0.36470588235294116, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09803921568627451, 0.5882352941176471, 0.9921568627450981, 0.9921568627450981, 0.9921568627450981, 0.9803921568627451, 0.3058823529411765, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10196078431372549, 0.6745098039215687, 0.3215686274509804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.10588235294117647, 0.7333333333333333, 0.9764705882352941, 0.8117647058823529, 0.7137254901960784, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6509803921568628, 0.9921568627450981, 0.3215686274509804, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.25098039215686274, 0.00784313725490196, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.9490196078431372, 0.2196078431372549, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9686274509803922, 0.7647058823529411, 0.15294117647058825, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4980392156862745, 0.25098039215686274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]"
     ]
    }
   ],
   "source": [
    "show(preprocess(images[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m! \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mert \u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mDims \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mexhull \u001b[0m\u001b[1mC\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22mTranspose ∇\u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mv\u001b[22m_data\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "Conv(size, in=>out)\n",
       "Conv(size, in=>out, relu)\n",
       "\\end{verbatim}\n",
       "Standard convolutional layer. \\texttt{size} should be a tuple like \\texttt{(2, 2)}. \\texttt{in} and \\texttt{out} specify the number of input and output channels respectively.\n",
       "\n",
       "Example: Applying Conv layer to a 1-channel input using a 2x2 window size,          giving us a 16-channel output. Output is activated with ReLU.\n",
       "\n",
       "\\begin{verbatim}\n",
       "size = (2,2)\n",
       "in = 1\n",
       "out = 16 \n",
       "Conv((2, 2), 1=>16, relu)\n",
       "\\end{verbatim}\n",
       "Data should be stored in WHCN order (width, height, \\# channels, \\# batches).  In other words, a 100×100 RGB image would be a \\texttt{100×100×3×1} array,  and a batch of 50 would be a \\texttt{100×100×3×50} array.\n",
       "\n",
       "Takes the keyword arguments \\texttt{pad}, \\texttt{stride} and \\texttt{dilation}.\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "Conv(size, in=>out)\n",
       "Conv(size, in=>out, relu)\n",
       "```\n",
       "\n",
       "Standard convolutional layer. `size` should be a tuple like `(2, 2)`. `in` and `out` specify the number of input and output channels respectively.\n",
       "\n",
       "Example: Applying Conv layer to a 1-channel input using a 2x2 window size,          giving us a 16-channel output. Output is activated with ReLU.\n",
       "\n",
       "```\n",
       "size = (2,2)\n",
       "in = 1\n",
       "out = 16 \n",
       "Conv((2, 2), 1=>16, relu)\n",
       "```\n",
       "\n",
       "Data should be stored in WHCN order (width, height, # channels, # batches).  In other words, a 100×100 RGB image would be a `100×100×3×1` array,  and a batch of 50 would be a `100×100×3×50` array.\n",
       "\n",
       "Takes the keyword arguments `pad`, `stride` and `dilation`.\n"
      ],
      "text/plain": [
       "\u001b[36m  Conv(size, in=>out)\u001b[39m\n",
       "\u001b[36m  Conv(size, in=>out, relu)\u001b[39m\n",
       "\n",
       "  Standard convolutional layer. \u001b[36msize\u001b[39m should be a tuple like \u001b[36m(2, 2)\u001b[39m. \u001b[36min\u001b[39m and \u001b[36mout\u001b[39m\n",
       "  specify the number of input and output channels respectively.\n",
       "\n",
       "  Example: Applying Conv layer to a 1-channel input using a 2x2 window size,\n",
       "  giving us a 16-channel output. Output is activated with ReLU.\n",
       "\n",
       "\u001b[36m  size = (2,2)\u001b[39m\n",
       "\u001b[36m  in = 1\u001b[39m\n",
       "\u001b[36m  out = 16 \u001b[39m\n",
       "\u001b[36m  Conv((2, 2), 1=>16, relu)\u001b[39m\n",
       "\n",
       "  Data should be stored in WHCN order (width, height, # channels, # batches).\n",
       "  In other words, a 100×100 RGB image would be a \u001b[36m100×100×3×1\u001b[39m array, and a\n",
       "  batch of 50 would be a \u001b[36m100×100×3×50\u001b[39m array.\n",
       "\n",
       "  Takes the keyword arguments \u001b[36mpad\u001b[39m, \u001b[36mstride\u001b[39m and \u001b[36mdilation\u001b[39m."
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?Conv"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.4",
   "language": "julia",
   "name": "juliapro_v1.4.2-1-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 3
}
